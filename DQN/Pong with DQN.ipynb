{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model,Sequential\n",
    "from tensorflow.keras.layers import Activation,Dense,Conv2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    \n",
    "    def __init__(self,mem_size,input_dim):\n",
    "        self.mem_size = mem_size\n",
    "        self.cntr = 0\n",
    "        \n",
    "        self.state_memory = np.zeros((mem_size,*input_dim),dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((mem_size,*input_dim),dtype=np.float32)\n",
    "        self.action_memory = np.zeros(mem_size,dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(mem_size,dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(mem_size,dtype=np.uint8)\n",
    "        \n",
    "    def store_exprience(self,state,action,reward,state_,done):\n",
    "        index = self.cntr % self.mem_size\n",
    "\n",
    "        self.state_memory[index] = state \n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        \n",
    "        self.cntr += 1\n",
    "        \n",
    "    def sample_exprience(self,batch_size):\n",
    "        \n",
    "        min_index = min(self.cntr,self.mem_size)\n",
    "        batch = np.random.choice(min_index,batch_size, replace=False)\n",
    "        \n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "                           \n",
    "        return states,actions,rewards,states_,dones\n",
    "                           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dqn(lr,n_actions,input_dims,fc1_dims):\n",
    "    model =Sequential()\n",
    "    model.add(Conv2D(filters=32,kernel_size=8,strides=4,activation='relu',\n",
    "                     input_shape=(*input_dims,),data_format='channels_first'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=4,strides=2,activation='relu',data_format='channels_first'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=3,strides=1,activation='relu',data_format='channels_first'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(fc1_dims,activation='relu'))\n",
    "    model.add(Dense(n_actions))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=lr),loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self,alpha,gamma,n_actions,epsilon,batch_size,replace,input_dims,\n",
    "                eps_dec=1e-5,eps_min=0.01,mem_size=1000000,q_eval_fname='q_eval.h5',\n",
    "                 q_target_fname='q_target.h5'):\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_dec = eps_dec\n",
    "        self.eps_min = eps_min\n",
    "        self.batch_size = batch_size\n",
    "        self.replace = replace\n",
    "        self.q_target_model_file = q_target_fname\n",
    "        self.q_eval_model_file = q_eval_fname\n",
    "        self.learn_step = 0\n",
    "        self.memory = ReplayBuffer(mem_size,input_dims)\n",
    "        self.q_eval = build_dqn(alpha,n_actions,input_dims,512)\n",
    "        self.q_next = build_dqn(alpha,n_actions,input_dims,512)\n",
    "        \n",
    "    def replace_target_network(self):\n",
    "        if self.replace != 0 and self.learn_step % self.replace == 0:\n",
    "            self.q_next.set_weights(self.q_eval.get_weights())\n",
    "\n",
    "    def store_transition(self,state,action,reward,state_,done):\n",
    "        self.memory.store_exprience(state,action,reward,state_,done)\n",
    "\n",
    "    def choose_action(self,observation):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            state = np.array([observation],copy=False,dtype=np.float32)\n",
    "            Q = self.q_eval.predict(state)\n",
    "            action = np.argmax(Q)\n",
    "\n",
    "        return action\n",
    "    def learn(self):\n",
    "        if self.memory.cntr >self.batch_size:\n",
    "            state,action,reward,new_state,done = self.memory.sample_exprience(self.batch_size)\n",
    "\n",
    "            self.replace_target_network()\n",
    "            q_eval = self.q_eval.predict(state)\n",
    "            q_next = self.q_next.predict(new_state)\n",
    "\n",
    "        \n",
    "            indices = np.arange(self.batch_size)\n",
    "            q_target = q_eval[:]\n",
    "            q_target[indices,action] = reward + self.gamma*np.max(q_next,axis=1)*(1 - done)\n",
    "\n",
    "            self.q_eval.train_on_batch(state,q_target)\n",
    "\n",
    "            self.epsilon = self.epsilon - self.eps_dec if self.epsilon>self.eps_min else self.eps_min\n",
    "\n",
    "            self.learn_step += 1\n",
    "\n",
    "    def save_model(self):\n",
    "        self.q_eval.save(self.q_eval_model_file)\n",
    "        self.q_next.save(self.q_target_model_file)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.q_eval=load_model(self.q_eval_model_file)\n",
    "        self.q_next = laod_model(self.q_target_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mujoco_py==2.0.2.8\n",
    "# !pip install 'gym[all]'\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(SkipEnv, self).__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        t_reward = 0.0\n",
    "        done = False\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            t_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, t_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self._obs_buffer = []\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(PreProcessFrame, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255,\n",
    "                                                shape=(80,80,1), dtype=np.uint8)\n",
    "    def observation(self, obs):\n",
    "        return PreProcessFrame.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "\n",
    "        new_frame = np.reshape(frame, frame.shape).astype(np.float32)\n",
    "\n",
    "        new_frame = 0.299*new_frame[:,:,0] + 0.587*new_frame[:,:,1] + \\\n",
    "                    0.114*new_frame[:,:,2]\n",
    "\n",
    "        new_frame = new_frame[35:195:2, ::2].reshape(80,80,1)\n",
    "\n",
    "        return new_frame.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleFrame(gym.ObservationWrapper):\n",
    "    def observation(self,obs):\n",
    "        return np.array(obs).astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "                             env.observation_space.low.repeat(n_steps, axis=0),\n",
    "                             env.observation_space.high.repeat(n_steps, axis=0),\n",
    "                             dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "#         print('reset',self.observation_space.low.shape)\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=np.float32)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "#         print('observation',observation.shape)\n",
    "#         print('observation444',self.buffer[:-1].shape)\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1,:,:] = observation\n",
    "        return self.buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoveImgChannel(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(MoveImgChannel, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0,\n",
    "                            shape=(self.observation_space.shape[-1],\n",
    "                                   self.observation_space.shape[0],\n",
    "                                   self.observation_space.shape[1]),\n",
    "                            dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = SkipEnv(env)\n",
    "    env = PreProcessFrame(env)\n",
    "    env = MoveImgChannel(env)\n",
    "    env = BufferWrapper(env,4)\n",
    "    return ScaleFrame(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = 250\n",
    "load_checkpoint =False\n",
    "best_score = -21\n",
    "agent = Agent(gamma=0.99,epsilon=1.0,alpha= 0.0001,input_dims=(4,80,80),n_actions=6,mem_size=25000,eps_min=0.02,batch_size=32,\n",
    "             replace=1000,eps_dec=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score -19.00 average_score -19.00 epsilone 0.99\n",
      "episode:  1 score -18.00 average_score -18.50 epsilone 0.98\n",
      "episode:  2 score -21.00 average_score -19.33 epsilone 0.97\n",
      "episode:  3 score -19.00 average_score -19.25 epsilone 0.96\n",
      "episode:  4 score -21.00 average_score -19.60 epsilone 0.95\n",
      "episode:  5 score -20.00 average_score -19.67 epsilone 0.94\n",
      "episode:  6 score -21.00 average_score -19.86 epsilone 0.93\n",
      "episode:  7 score -20.00 average_score -19.88 epsilone 0.92\n",
      "episode:  8 score -19.00 average_score -19.78 epsilone 0.91\n",
      "episode:  9 score -19.00 average_score -19.70 epsilone 0.91\n",
      "episode:  10 score -21.00 average_score -19.82 epsilone 0.90\n",
      "episode:  11 score -20.00 average_score -19.83 epsilone 0.89\n",
      "episode:  12 score -19.00 average_score -19.77 epsilone 0.88\n",
      "episode:  13 score -21.00 average_score -19.86 epsilone 0.87\n",
      "episode:  14 score -21.00 average_score -19.93 epsilone 0.86\n",
      "episode:  15 score -19.00 average_score -19.88 epsilone 0.85\n",
      "episode:  16 score -21.00 average_score -19.94 epsilone 0.84\n",
      "episode:  17 score -21.00 average_score -20.00 epsilone 0.83\n",
      "episode:  18 score -21.00 average_score -20.05 epsilone 0.83\n",
      "episode:  19 score -20.00 average_score -20.05 epsilone 0.82\n",
      "episode:  20 score -19.00 average_score -20.00 epsilone 0.80\n",
      "episode:  21 score -21.00 average_score -20.05 epsilone 0.79\n",
      "episode:  22 score -19.00 average_score -20.00 epsilone 0.78\n",
      "episode:  23 score -21.00 average_score -20.04 epsilone 0.78\n",
      "episode:  24 score -20.00 average_score -20.04 epsilone 0.77\n",
      "episode:  25 score -21.00 average_score -20.08 epsilone 0.76\n",
      "episode:  26 score -20.00 average_score -20.07 epsilone 0.75\n",
      "episode:  27 score -21.00 average_score -20.11 epsilone 0.74\n",
      "episode:  28 score -21.00 average_score -20.14 epsilone 0.73\n",
      "episode:  29 score -21.00 average_score -20.17 epsilone 0.72\n",
      "episode:  30 score -19.00 average_score -20.13 epsilone 0.71\n",
      "episode:  31 score -20.00 average_score -20.12 epsilone 0.70\n",
      "episode:  32 score -21.00 average_score -20.15 epsilone 0.69\n",
      "episode:  33 score -20.00 average_score -20.15 epsilone 0.68\n",
      "episode:  34 score -21.00 average_score -20.17 epsilone 0.68\n",
      "episode:  35 score -21.00 average_score -20.19 epsilone 0.67\n",
      "episode:  36 score -21.00 average_score -20.22 epsilone 0.66\n",
      "episode:  37 score -20.00 average_score -20.21 epsilone 0.65\n",
      "episode:  38 score -21.00 average_score -20.23 epsilone 0.64\n",
      "episode:  39 score -21.00 average_score -20.25 epsilone 0.63\n",
      "episode:  40 score -21.00 average_score -20.27 epsilone 0.62\n",
      "episode:  41 score -20.00 average_score -20.26 epsilone 0.61\n",
      "episode:  42 score -21.00 average_score -20.28 epsilone 0.60\n",
      "episode:  43 score -18.00 average_score -20.23 epsilone 0.59\n",
      "episode:  44 score -20.00 average_score -20.22 epsilone 0.58\n",
      "episode:  45 score -21.00 average_score -20.24 epsilone 0.57\n",
      "episode:  46 score -20.00 average_score -20.23 epsilone 0.55\n",
      "episode:  47 score -20.00 average_score -20.23 epsilone 0.54\n",
      "episode:  48 score -19.00 average_score -20.20 epsilone 0.53\n",
      "episode:  49 score -19.00 average_score -20.18 epsilone 0.52\n",
      "episode:  50 score -20.00 average_score -20.18 epsilone 0.51\n",
      "episode:  51 score -18.00 average_score -20.13 epsilone 0.50\n",
      "episode:  52 score -17.00 average_score -20.08 epsilone 0.48\n",
      "episode:  53 score -19.00 average_score -20.06 epsilone 0.47\n",
      "episode:  54 score -19.00 average_score -20.04 epsilone 0.45\n",
      "episode:  55 score -18.00 average_score -20.00 epsilone 0.44\n",
      "episode:  56 score -17.00 average_score -19.95 epsilone 0.42\n",
      "episode:  57 score -14.00 average_score -19.84 epsilone 0.40\n",
      "episode:  58 score -12.00 average_score -19.71 epsilone 0.39\n",
      "episode:  59 score -15.00 average_score -19.63 epsilone 0.37\n",
      "episode:  60 score -19.00 average_score -19.62 epsilone 0.35\n",
      "episode:  61 score -17.00 average_score -19.58 epsilone 0.33\n",
      "episode:  62 score -19.00 average_score -19.57 epsilone 0.32\n",
      "episode:  63 score -17.00 average_score -19.53 epsilone 0.30\n",
      "episode:  64 score -11.00 average_score -19.40 epsilone 0.28\n",
      "episode:  65 score -14.00 average_score -19.32 epsilone 0.26\n",
      "episode:  66 score -20.00 average_score -19.33 epsilone 0.24\n",
      "episode:  67 score -21.00 average_score -19.35 epsilone 0.23\n",
      "episode:  68 score -18.00 average_score -19.33 epsilone 0.21\n",
      "episode:  69 score -15.00 average_score -19.27 epsilone 0.19\n",
      "episode:  70 score -12.00 average_score -19.17 epsilone 0.17\n",
      "episode:  71 score -15.00 average_score -19.11 epsilone 0.15\n",
      "episode:  72 score -17.00 average_score -19.08 epsilone 0.13\n",
      "episode:  73 score -13.00 average_score -19.00 epsilone 0.10\n",
      "episode:  74 score -11.00 average_score -18.89 epsilone 0.08\n",
      "episode:  75 score -14.00 average_score -18.83 epsilone 0.06\n",
      "episode:  76 score -15.00 average_score -18.78 epsilone 0.03\n",
      "episode:  77 score -10.00 average_score -18.67 epsilone 0.02\n",
      "episode:  78 score -15.00 average_score -18.62 epsilone 0.02\n",
      "episode:  79 score -3.00 average_score -18.43 epsilone 0.02\n",
      "episode:  80 score -9.00 average_score -18.31 epsilone 0.02\n",
      "episode:  81 score -7.00 average_score -18.17 epsilone 0.02\n",
      "episode:  82 score -3.00 average_score -17.99 epsilone 0.02\n",
      "episode:  83 score 1.00 average_score -17.76 epsilone 0.02\n",
      "episode:  84 score -14.00 average_score -17.72 epsilone 0.02\n",
      "episode:  85 score -7.00 average_score -17.59 epsilone 0.02\n",
      "episode:  86 score -13.00 average_score -17.54 epsilone 0.02\n",
      "episode:  87 score 11.00 average_score -17.22 epsilone 0.02\n",
      "episode:  88 score -4.00 average_score -17.07 epsilone 0.02\n",
      "episode:  89 score 12.00 average_score -16.74 epsilone 0.02\n",
      "episode:  90 score 20.00 average_score -16.34 epsilone 0.02\n",
      "episode:  91 score 10.00 average_score -16.05 epsilone 0.02\n",
      "episode:  92 score 17.00 average_score -15.70 epsilone 0.02\n",
      "episode:  93 score 12.00 average_score -15.40 epsilone 0.02\n",
      "episode:  94 score 15.00 average_score -15.08 epsilone 0.02\n",
      "episode:  95 score 19.00 average_score -14.73 epsilone 0.02\n",
      "episode:  96 score 15.00 average_score -14.42 epsilone 0.02\n",
      "episode:  97 score 16.00 average_score -14.11 epsilone 0.02\n",
      "episode:  98 score 20.00 average_score -13.77 epsilone 0.02\n",
      "episode:  99 score 18.00 average_score -13.45 epsilone 0.02\n",
      "episode:  100 score 18.00 average_score -13.08 epsilone 0.02\n",
      "episode:  101 score 18.00 average_score -12.72 epsilone 0.02\n",
      "episode:  102 score 19.00 average_score -12.32 epsilone 0.02\n",
      "episode:  103 score 6.00 average_score -12.07 epsilone 0.02\n",
      "episode:  104 score 18.00 average_score -11.68 epsilone 0.02\n",
      "episode:  105 score 18.00 average_score -11.30 epsilone 0.02\n",
      "episode:  106 score 10.00 average_score -10.99 epsilone 0.02\n",
      "episode:  107 score 15.00 average_score -10.64 epsilone 0.02\n",
      "episode:  108 score 8.00 average_score -10.37 epsilone 0.02\n",
      "episode:  109 score 11.00 average_score -10.07 epsilone 0.02\n",
      "episode:  110 score 12.00 average_score -9.74 epsilone 0.02\n",
      "episode:  111 score 13.00 average_score -9.41 epsilone 0.02\n",
      "episode:  112 score 11.00 average_score -9.11 epsilone 0.02\n",
      "episode:  113 score 13.00 average_score -8.77 epsilone 0.02\n",
      "episode:  114 score 10.00 average_score -8.46 epsilone 0.02\n",
      "episode:  115 score 17.00 average_score -8.10 epsilone 0.02\n",
      "episode:  116 score 15.00 average_score -7.74 epsilone 0.02\n",
      "episode:  117 score 13.00 average_score -7.40 epsilone 0.02\n",
      "episode:  118 score 16.00 average_score -7.03 epsilone 0.02\n",
      "episode:  119 score 15.00 average_score -6.68 epsilone 0.02\n",
      "episode:  120 score 21.00 average_score -6.28 epsilone 0.02\n",
      "episode:  121 score 12.00 average_score -5.95 epsilone 0.02\n",
      "episode:  122 score 15.00 average_score -5.61 epsilone 0.02\n",
      "episode:  123 score 7.00 average_score -5.33 epsilone 0.02\n",
      "episode:  124 score 19.00 average_score -4.94 epsilone 0.02\n",
      "episode:  125 score 21.00 average_score -4.52 epsilone 0.02\n",
      "episode:  126 score 15.00 average_score -4.17 epsilone 0.02\n",
      "episode:  127 score 17.00 average_score -3.79 epsilone 0.02\n",
      "episode:  128 score 14.00 average_score -3.44 epsilone 0.02\n",
      "episode:  129 score 21.00 average_score -3.02 epsilone 0.02\n",
      "episode:  130 score 20.00 average_score -2.63 epsilone 0.02\n",
      "episode:  131 score 21.00 average_score -2.22 epsilone 0.02\n",
      "episode:  132 score 20.00 average_score -1.81 epsilone 0.02\n",
      "episode:  133 score 16.00 average_score -1.45 epsilone 0.02\n",
      "episode:  134 score 18.00 average_score -1.06 epsilone 0.02\n",
      "episode:  135 score 21.00 average_score -0.64 epsilone 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  136 score 19.00 average_score -0.24 epsilone 0.02\n",
      "episode:  137 score 20.00 average_score 0.16 epsilone 0.02\n",
      "episode:  138 score 21.00 average_score 0.58 epsilone 0.02\n",
      "episode:  139 score 19.00 average_score 0.98 epsilone 0.02\n",
      "episode:  140 score 17.00 average_score 1.36 epsilone 0.02\n",
      "episode:  141 score 21.00 average_score 1.77 epsilone 0.02\n",
      "episode:  142 score 20.00 average_score 2.18 epsilone 0.02\n",
      "episode:  143 score 21.00 average_score 2.57 epsilone 0.02\n",
      "episode:  144 score 7.00 average_score 2.84 epsilone 0.02\n",
      "episode:  145 score 12.00 average_score 3.17 epsilone 0.02\n",
      "episode:  146 score 12.00 average_score 3.49 epsilone 0.02\n",
      "episode:  147 score 7.00 average_score 3.76 epsilone 0.02\n",
      "episode:  148 score 12.00 average_score 4.07 epsilone 0.02\n",
      "episode:  149 score 13.00 average_score 4.39 epsilone 0.02\n",
      "episode:  150 score 21.00 average_score 4.80 epsilone 0.02\n",
      "episode:  151 score 19.00 average_score 5.17 epsilone 0.02\n",
      "episode:  152 score 5.00 average_score 5.39 epsilone 0.02\n",
      "episode:  153 score 14.00 average_score 5.72 epsilone 0.02\n",
      "episode:  154 score 20.00 average_score 6.11 epsilone 0.02\n",
      "episode:  155 score 19.00 average_score 6.48 epsilone 0.02\n",
      "episode:  156 score 20.00 average_score 6.85 epsilone 0.02\n",
      "episode:  157 score 16.00 average_score 7.15 epsilone 0.02\n",
      "episode:  158 score 21.00 average_score 7.48 epsilone 0.02\n",
      "episode:  159 score 17.00 average_score 7.80 epsilone 0.02\n",
      "episode:  160 score 19.00 average_score 8.18 epsilone 0.02\n",
      "episode:  161 score 21.00 average_score 8.56 epsilone 0.02\n",
      "episode:  162 score 11.00 average_score 8.86 epsilone 0.02\n",
      "episode:  163 score 10.00 average_score 9.13 epsilone 0.02\n",
      "episode:  164 score 12.00 average_score 9.36 epsilone 0.02\n",
      "episode:  165 score 21.00 average_score 9.71 epsilone 0.02\n",
      "episode:  166 score 17.00 average_score 10.08 epsilone 0.02\n",
      "episode:  167 score 15.00 average_score 10.44 epsilone 0.02\n",
      "episode:  168 score 21.00 average_score 10.83 epsilone 0.02\n",
      "episode:  169 score 19.00 average_score 11.17 epsilone 0.02\n",
      "episode:  170 score 19.00 average_score 11.48 epsilone 0.02\n",
      "episode:  171 score 21.00 average_score 11.84 epsilone 0.02\n",
      "episode:  172 score 21.00 average_score 12.22 epsilone 0.02\n",
      "episode:  173 score 20.00 average_score 12.55 epsilone 0.02\n",
      "episode:  174 score 21.00 average_score 12.87 epsilone 0.02\n",
      "episode:  175 score 19.00 average_score 13.20 epsilone 0.02\n",
      "episode:  176 score 16.00 average_score 13.51 epsilone 0.02\n",
      "episode:  177 score 21.00 average_score 13.82 epsilone 0.02\n",
      "episode:  178 score 19.00 average_score 14.16 epsilone 0.02\n",
      "episode:  179 score 18.00 average_score 14.37 epsilone 0.02\n",
      "episode:  180 score 20.00 average_score 14.66 epsilone 0.02\n",
      "episode:  181 score 21.00 average_score 14.94 epsilone 0.02\n",
      "episode:  182 score 19.00 average_score 15.16 epsilone 0.02\n",
      "episode:  183 score 18.00 average_score 15.33 epsilone 0.02\n",
      "episode:  184 score 19.00 average_score 15.66 epsilone 0.02\n",
      "episode:  185 score 21.00 average_score 15.94 epsilone 0.02\n",
      "episode:  186 score 19.00 average_score 16.26 epsilone 0.02\n",
      "episode:  187 score 19.00 average_score 16.34 epsilone 0.02\n",
      "episode:  188 score 15.00 average_score 16.53 epsilone 0.02\n",
      "episode:  189 score 19.00 average_score 16.60 epsilone 0.02\n",
      "episode:  190 score 18.00 average_score 16.58 epsilone 0.02\n",
      "episode:  191 score 20.00 average_score 16.68 epsilone 0.02\n",
      "episode:  192 score 8.00 average_score 16.59 epsilone 0.02\n",
      "episode:  193 score 20.00 average_score 16.67 epsilone 0.02\n",
      "episode:  194 score 21.00 average_score 16.73 epsilone 0.02\n",
      "episode:  195 score 21.00 average_score 16.75 epsilone 0.02\n",
      "episode:  196 score 21.00 average_score 16.81 epsilone 0.02\n",
      "episode:  197 score 20.00 average_score 16.85 epsilone 0.02\n",
      "episode:  198 score 17.00 average_score 16.82 epsilone 0.02\n",
      "episode:  199 score 9.00 average_score 16.73 epsilone 0.02\n",
      "episode:  200 score 21.00 average_score 16.76 epsilone 0.02\n",
      "episode:  201 score 13.00 average_score 16.71 epsilone 0.02\n",
      "episode:  202 score 11.00 average_score 16.63 epsilone 0.02\n",
      "episode:  203 score 20.00 average_score 16.77 epsilone 0.02\n",
      "episode:  204 score 20.00 average_score 16.79 epsilone 0.02\n",
      "episode:  205 score 17.00 average_score 16.78 epsilone 0.02\n",
      "episode:  206 score 8.00 average_score 16.76 epsilone 0.02\n",
      "episode:  207 score 21.00 average_score 16.82 epsilone 0.02\n",
      "episode:  208 score 19.00 average_score 16.93 epsilone 0.02\n",
      "episode:  209 score 21.00 average_score 17.03 epsilone 0.02\n",
      "episode:  210 score 17.00 average_score 17.08 epsilone 0.02\n",
      "episode:  211 score 20.00 average_score 17.15 epsilone 0.02\n",
      "episode:  212 score 20.00 average_score 17.24 epsilone 0.02\n",
      "episode:  213 score 18.00 average_score 17.29 epsilone 0.02\n",
      "episode:  214 score 21.00 average_score 17.40 epsilone 0.02\n",
      "episode:  215 score 20.00 average_score 17.43 epsilone 0.02\n",
      "episode:  216 score 21.00 average_score 17.49 epsilone 0.02\n",
      "episode:  217 score 18.00 average_score 17.54 epsilone 0.02\n",
      "episode:  218 score 20.00 average_score 17.58 epsilone 0.02\n",
      "episode:  219 score 21.00 average_score 17.64 epsilone 0.02\n",
      "episode:  220 score 19.00 average_score 17.62 epsilone 0.02\n",
      "episode:  221 score 21.00 average_score 17.71 epsilone 0.02\n",
      "episode:  222 score 18.00 average_score 17.74 epsilone 0.02\n",
      "episode:  223 score 17.00 average_score 17.84 epsilone 0.02\n",
      "episode:  224 score 21.00 average_score 17.86 epsilone 0.02\n",
      "episode:  225 score 19.00 average_score 17.84 epsilone 0.02\n",
      "episode:  226 score 18.00 average_score 17.87 epsilone 0.02\n",
      "episode:  227 score 17.00 average_score 17.87 epsilone 0.02\n",
      "episode:  228 score 17.00 average_score 17.90 epsilone 0.02\n",
      "episode:  229 score 21.00 average_score 17.90 epsilone 0.02\n",
      "episode:  230 score 19.00 average_score 17.89 epsilone 0.02\n",
      "episode:  231 score 18.00 average_score 17.86 epsilone 0.02\n",
      "episode:  232 score 20.00 average_score 17.86 epsilone 0.02\n",
      "episode:  233 score 20.00 average_score 17.90 epsilone 0.02\n",
      "episode:  234 score 19.00 average_score 17.91 epsilone 0.02\n",
      "episode:  235 score 21.00 average_score 17.91 epsilone 0.02\n",
      "episode:  236 score 21.00 average_score 17.93 epsilone 0.02\n",
      "episode:  237 score 10.00 average_score 17.83 epsilone 0.02\n",
      "episode:  238 score 18.00 average_score 17.80 epsilone 0.02\n",
      "episode:  239 score 18.00 average_score 17.79 epsilone 0.02\n",
      "episode:  240 score 20.00 average_score 17.82 epsilone 0.02\n",
      "episode:  241 score 15.00 average_score 17.76 epsilone 0.02\n",
      "episode:  242 score 19.00 average_score 17.75 epsilone 0.02\n",
      "episode:  243 score 18.00 average_score 17.72 epsilone 0.02\n",
      "episode:  244 score 21.00 average_score 17.86 epsilone 0.02\n",
      "episode:  245 score 19.00 average_score 17.93 epsilone 0.02\n",
      "episode:  246 score 20.00 average_score 18.01 epsilone 0.02\n",
      "episode:  247 score 18.00 average_score 18.12 epsilone 0.02\n",
      "episode:  248 score 20.00 average_score 18.20 epsilone 0.02\n",
      "episode:  249 score 20.00 average_score 18.27 epsilone 0.02\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "eps_history =[]\n",
    "n_steps = 0\n",
    "for i in range(num_games):\n",
    "    score =0 \n",
    "    observation = env.reset()\n",
    "    done =False\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        observation_,reward,done,info = env.step(action)\n",
    "        n_steps +=1\n",
    "        score += reward\n",
    "        \n",
    "        agent.store_transition(observation,action,reward,observation_,int(done))\n",
    "        agent.learn()\n",
    "        \n",
    "#         env_render()\n",
    "        observation = observation_\n",
    "    scores.append(score)\n",
    "    avg_score = np.mean(scores[-100:])\n",
    "    print('episode: ',i,'score %.2f' % score,\n",
    "             'average_score %.2f' % avg_score,\n",
    "             'epsilone %.2f' % agent.epsilon)\n",
    "    if avg_score > best_score:\n",
    "        agent.save_model()\n",
    "        best_score = avg_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
